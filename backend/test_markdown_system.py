#!/usr/bin/env python3
"""
Comprehensive Test Suite for Markdown System

Test cases:
1. ìƒ‰ì€ì‹ calculation verification
2. NLP content generation quality
3. Markdown format validation
4. API endpoint testing
5. Complete pipeline integration

Usage:
    pytest test_markdown_system.py -v
    pytest test_markdown_system.py::TestSaekeunshik -v
    pytest test_markdown_system.py::TestNLPContent -v
    pytest test_markdown_system.py::TestMarkdownGeneration -v
    pytest test_markdown_system.py::TestAPIEndpoints -v
    pytest test_markdown_system.py::TestPipeline -v
"""

import pytest
import json
import sys
from datetime import date, datetime, time
from pathlib import Path
from typing import Dict, List, Any
import re

# Add backend to path
sys.path.insert(0, str(Path(__file__).parent))

from generate_daily_markdown import DailyMarkdownGenerator
from src.rhythm.models import BirthInfo, Gender
from src.rhythm.saju import calculate_saju, analyze_daily_fortune
from src.content.assembly import assemble_daily_content


# ============================================================================
# TEST DATA - ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‚¬ì£¼ (1971ë…„ 11ì›” 17ì¼ 04:00 ì–‘ë ¥ ë‚¨ì)
# ============================================================================

@pytest.fixture
def test_birth_info():
    """í…ŒìŠ¤íŠ¸ ì‚¬ì£¼ ê¸°ë³¸ ì •ë³´"""
    return BirthInfo(
        name="í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì",
        birth_date=date(1971, 11, 17),
        birth_time=time(4, 0),
        gender=Gender.MALE,
        birth_place="ì„œìš¸",
        birth_place_lat=37.5665,
        birth_place_lng=126.9780
    )


@pytest.fixture
def test_target_date():
    """í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ë‚ ì§œ"""
    return date(2026, 1, 31)


@pytest.fixture
def sample_energy_data():
    """ìƒ˜í”Œ ì—ë„ˆì§€ JSON ë°ì´í„°"""
    return {
        "date": "2026-01-31",
        "energy": {
            "rhythm_label": "í™œë™ì ",
            "intensity_level": "ë†’ìŒ",
            "focus_level": "ë†’ìŒ",
            "recovery_need": "ë‚®ìŒ",
            "decision_level": "ë†’ìŒ",
            "social_level": "ë†’ìŒ"
        },
        "keywords": {
            "scores": {
                "í™œë™": 0.95,
                "ì§‘ì¤‘": 0.90,
                "ê²°ì •": 0.85,
                "ê´€ê³„": 0.80,
                "ë¦¬ë”ì‹­": 0.75,
                "ì°½ì˜": 0.70,
                "íš¨ìœ¨": 0.65,
                "ì„±ì¥": 0.60,
                "ë„ì „": 0.55,
                "ë³€í™”": 0.50
            }
        },
        "flags": {
            "fatigue_risk": False,
            "overpromise_risk": False,
            "conflict_risk": False,
            "spending_risk": False,
            "mistake_risk": False
        },
        "lifestyle": {
            "reco": {
                "health": {
                    "do": ["í™œë™ì ì¸ ìš´ë™", "ì•¼ì™¸ í™œë™"],
                    "avoid": ["ê³¼ë¡œ", "ë¬´ë¦¬í•œ ì²´ë ¥"],
                    "tip": "ì—ë„ˆì§€ê°€ ë†’ì€ ë‚ ì´ë¯€ë¡œ ìš´ë™ìœ¼ë¡œ í™œìš©í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤"
                },
                "food": {
                    "do": ["ê· í˜•ì¡íŒ ì‹ì‚¬", "ë‹¨ë°±ì§ˆ"],
                    "avoid": ["ê³¼ì‹", "ìê·¹ì ì¸ ìŒì‹"],
                    "tip": "ì¶©ë¶„í•œ ì˜ì–‘ì„­ì·¨ë¡œ ì—ë„ˆì§€ ìœ ì§€í•˜ê¸°"
                },
                "fashion": {
                    "do": ["ë°ì€ ìƒ‰ìƒ", "í¸ì•ˆí•œ ì˜ë¥˜"],
                    "avoid": ["ë„ˆë¬´ íƒ€ì´íŠ¸í•œ ì˜·"],
                    "tip": "í¸í•œ ë³µì¥ìœ¼ë¡œ í™œë™ì„± ë†’ì´ê¸°"
                },
                "finance": {
                    "do": ["ê³„íšì  ì†Œë¹„", "íˆ¬ì ê³ ë ¤"],
                    "avoid": ["ì¶©ë™ êµ¬ë§¤"],
                    "tip": "íŒë‹¨ë ¥ì´ ì¢‹ìœ¼ë‹ˆ í° ê²°ì • ë‚´ë¦¬ê¸° ì¢‹ì€ ë‚ "
                },
                "space": {
                    "do": ["ì •ë¦¬ì •ëˆ", "ì¸í…Œë¦¬ì–´"],
                    "avoid": ["ì–´ìˆ˜ì„ í•œ ê³µê°„ ìœ ì§€"],
                    "tip": "ì§‘ì¤‘ë ¥ì´ ë†’ìœ¼ë‹ˆ ì •ë¦¬ì‘ì—… ì¶”ì§„í•˜ê¸°"
                },
                "routine": {
                    "do": ["ê·œì¹™ì  ë£¨í‹´", "ì•„ì¹¨ í™œë™"],
                    "avoid": ["ëŠ¦ê²Œ ì¼ì–´ë‚˜ê¸°"],
                    "tip": "ì•„ì¹¨ë¶€í„° í™œë™ì ìœ¼ë¡œ ì‹œì‘í•˜ê¸°"
                },
                "digital": {
                    "do": ["í™œë°œí•œ ì†Œí†µ", "SNS í™œìš©"],
                    "avoid": ["ê³¼ë„í•œ ë””ì§€í„¸"],
                    "tip": "ì‚¬ëŒê³¼ì˜ ì—°ê²°ì´ í™œë°œí•œ ë‚ "
                },
                "hobby": {
                    "do": ["ìƒˆë¡œìš´ ì‹œë„", "ì°½ì‘ í™œë™"],
                    "avoid": ["ì·¨ë¯¸ ë¯¸ë£¨ê¸°"],
                    "tip": "ì°½ì˜ë ¥ì´ ë†’ìœ¼ë‹ˆ ìƒˆë¡œìš´ ì‹œë„ ì¶”ì§„"
                },
                "social": {
                    "do": ["ì•½ì† ì¡ê¸°", "ë„¤íŠ¸ì›Œí‚¹"],
                    "avoid": ["í˜¼ìë§Œ ìˆê¸°"],
                    "tip": "ê´€ê³„ í™œë™ì´ ìì—°ìŠ¤ëŸ¬ìš´ ë‚ "
                },
                "season": {
                    "do": ["ê²¨ìš¸ ì˜·ì°¨ë¦¼", "ì‹¤ë‚´ í™œë™"],
                    "avoid": ["ì™¸ì¶œ ë¯¸ë£¨ê¸°"],
                    "tip": "ê²¨ìš¸ ë‚ ì”¨ì— í™œë™ì ìœ¼ë¡œ ì›€ì§ì´ê¸°"
                }
            }
        }
    }


@pytest.fixture
def sample_time_direction_data():
    """ìƒ˜í”Œ ì‹œê°„/ë°©í–¥ JSON ë°ì´í„°"""
    return {
        "date": "2026-01-31",
        "qimen": {
            "good_windows": [
                {
                    "start": "09:00",
                    "end": "11:00",
                    "reason_plain": "ì˜¤ì „ ì—ë„ˆì§€ê°€ ê°€ì¥ ì¢‹ì€ ì‹œê°„ëŒ€ë¡œ, ì¤‘ìš”í•œ ì—…ë¬´ë‚˜ ê²°ì •ì— ì í•©í•©ë‹ˆë‹¤"
                },
                {
                    "start": "14:00",
                    "end": "16:00",
                    "reason_plain": "ì˜¤í›„ ì§‘ì¤‘ë ¥ ì •ì ìœ¼ë¡œ, ê¹Šì´ ìˆëŠ” ì‘ì—…ì— ìµœì ì…ë‹ˆë‹¤"
                }
            ],
            "avoid_windows": [
                {
                    "start": "17:00",
                    "end": "19:00",
                    "reason_plain": "ì €ë… ì—ë„ˆì§€ ì €í•˜ë¡œ, ì¤‘ìš”í•œ ê²°ì •ì€ í”¼í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤"
                }
            ],
            "good_directions": ["ë¶ë™", "ë‚¨"],
            "avoid_directions": ["ì„œ"]
        }
    }


# ============================================================================
# TEST 1: ìƒ‰ì€ì‹(Saekeunshik) Calculation Verification
# ============================================================================

class TestSaekeunshik:
    """ìƒ‰ì€ì‹ ê³„ì‚° ê²€ì¦ í…ŒìŠ¤íŠ¸"""

    def test_five_movements_exist(self, test_birth_info, test_target_date):
        """ì˜¤í–‰(Five Movements) ê³„ì‚°ì´ ìˆ˜í–‰ë˜ëŠ”ì§€ í™•ì¸"""
        # Saju ê³„ì‚° (target_date í¬í•¨)
        try:
            saju_result = calculate_saju(test_birth_info, test_target_date)

            # ê²°ê³¼ê°€ dictì´ê³  í•„ìˆ˜ í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            assert isinstance(saju_result, dict)
            assert "ì‚¬ì£¼" in saju_result or "ì˜¤í–‰" in saju_result or "ì‹­ì„±" in saju_result
        except RuntimeError as e:
            # Node.jsê°€ ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ
            if "cli.js" in str(e) or "node" in str(e).lower():
                pytest.skip(f"Saju ê³„ì‚°ê¸° ë¶€ì¬: {e}")
            raise

    def test_six_qi_calculation(self, test_birth_info, test_target_date):
        """ìœ¡ê¸°(Six Qi) ê³„ì‚° ê²€ì¦"""
        # Saju ê³„ì‚° ë¨¼ì € ìˆ˜í–‰
        try:
            saju_result = calculate_saju(test_birth_info, test_target_date)
        except RuntimeError as e:
            if "cli.js" in str(e) or "node" in str(e).lower():
                pytest.skip(f"Saju ê³„ì‚°ê¸° ë¶€ì¬: {e}")
            raise

        # ì¼ê°„ ë¶„ì„ (saju_data í•„ìˆ˜)
        from src.rhythm.saju import analyze_daily_fortune as analyze_fortune
        fortune = analyze_fortune(test_birth_info, test_target_date, saju_result)

        # ê²°ê³¼ê°€ dictì´ê³  ê¸°ë³¸ êµ¬ì¡°ê°€ ìˆëŠ”ì§€ í™•ì¸
        assert isinstance(fortune, dict)
        assert len(fortune) > 0
        assert "ì—ë„ˆì§€_ìˆ˜ì¤€" in fortune or "ì§‘ì¤‘ë ¥" in fortune

    def test_energy_integration_with_json(self, sample_energy_data):
        """ì—ë„ˆì§€ ë°ì´í„° JSONê³¼ì˜ ì—°ë™ í™•ì¸"""
        # ì—ë„ˆì§€ JSONì´ ìœ íš¨í•œ êµ¬ì¡°ì¸ì§€ í™•ì¸
        assert "energy" in sample_energy_data
        assert "keywords" in sample_energy_data
        assert "flags" in sample_energy_data
        assert "lifestyle" in sample_energy_data

        # ì—ë„ˆì§€ í•„ë“œ í™•ì¸
        energy = sample_energy_data["energy"]
        assert "rhythm_label" in energy
        assert "intensity_level" in energy
        assert "focus_level" in energy
        assert "recovery_need" in energy
        assert "decision_level" in energy
        assert "social_level" in energy

    def test_time_direction_integration(self, sample_time_direction_data):
        """ì‹œê°„/ë°©í–¥ ë°ì´í„° JSONê³¼ì˜ ì—°ë™ í™•ì¸"""
        assert "qimen" in sample_time_direction_data

        qimen = sample_time_direction_data["qimen"]
        assert "good_windows" in qimen
        assert "avoid_windows" in qimen
        assert "good_directions" in qimen
        assert "avoid_directions" in qimen


# ============================================================================
# TEST 2: NLP Content Generation Quality
# ============================================================================

class TestNLPContent:
    """NLP ì½˜í…ì¸  ìƒì„± í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""

    def test_character_count_minimum(self, sample_energy_data, sample_time_direction_data):
        """ìµœì†Œ ê¸€ì ìˆ˜ ìš”êµ¬ì‚¬í•­ (400-600ì) ê²€ì¦"""
        # Markdown ìƒì„±
        # ì„ì‹œ ê²½ë¡œì— JSON íŒŒì¼ ì €ì¥
        import tempfile
        import os

        with tempfile.TemporaryDirectory() as tmpdir:
            energy_path = os.path.join(tmpdir, "energy.json")
            time_path = os.path.join(tmpdir, "time.json")

            with open(energy_path, 'w', encoding='utf-8') as f:
                json.dump(sample_energy_data, f, ensure_ascii=False)

            with open(time_path, 'w', encoding='utf-8') as f:
                json.dump(sample_time_direction_data, f, ensure_ascii=False)

            generator = DailyMarkdownGenerator(energy_path, time_path)
            markdown = generator.generate_markdown()

            # ê¸€ì ìˆ˜ ê³„ì‚° (ê³µë°±, ì¤„ë°”ê¿ˆ ì œì™¸)
            char_count = len(markdown.replace(" ", "").replace("\n", ""))

            # ìµœì†Œ 400ì ì´ìƒ
            assert char_count >= 400, f"ê¸€ì ìˆ˜ ë¶€ì¡±: {char_count}ì (ìµœì†Œ 400ì í•„ìš”)"

            # ëª©í‘œ 700+ ì í™•ì¸
            if char_count >= 700:
                print(f"âœ… ëª©í‘œ ë‹¬ì„±: {char_count}ì (700+ ì)")
            else:
                print(f"âš ï¸  ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±: {char_count}ì (400+ ì)")

    def test_no_technical_terms(self, sample_energy_data, sample_time_direction_data):
        """ì‚¬ìš©ì ë…¸ì¶œ í…ìŠ¤íŠ¸ì—ì„œ ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ê¸ˆì§€"""
        import tempfile
        import os

        with tempfile.TemporaryDirectory() as tmpdir:
            energy_path = os.path.join(tmpdir, "energy.json")
            time_path = os.path.join(tmpdir, "time.json")

            with open(energy_path, 'w', encoding='utf-8') as f:
                json.dump(sample_energy_data, f, ensure_ascii=False)

            with open(time_path, 'w', encoding='utf-8') as f:
                json.dump(sample_time_direction_data, f, ensure_ascii=False)

            generator = DailyMarkdownGenerator(energy_path, time_path)
            markdown = generator.generate_markdown()

            # ê¸ˆì§€ ìš©ì–´ ë¦¬ìŠ¤íŠ¸
            forbidden_terms = [
                "ì‚¬ì£¼", "ì²œê°„", "ì§€ì§€", "ì˜¤í–‰", "ì‹­ì„±",
                "ëŒ€ìš´", "ì„¸ìš´", "ì›”ìš´", "ê¸°ë¬¸ë‘”ê°‘", "ë‚©ìŒ",
                "NLP", "ì•Œê³ ë¦¬ì¦˜", "ì—”ì§„", "ê³„ì‚° ëª¨ë“ˆ"
            ]

            # ê° ê¸ˆì§€ ìš©ì–´ í™•ì¸
            for term in forbidden_terms:
                assert term not in markdown, f"ê¸ˆì§€ëœ ìš©ì–´ '{term}'ì´ ì½˜í…ì¸ ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤"

    def test_natural_language_quality(self, sample_energy_data, sample_time_direction_data):
        """ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ í‘œí˜„ ê²€ì¦"""
        import tempfile
        import os

        with tempfile.TemporaryDirectory() as tmpdir:
            energy_path = os.path.join(tmpdir, "energy.json")
            time_path = os.path.join(tmpdir, "time.json")

            with open(energy_path, 'w', encoding='utf-8') as f:
                json.dump(sample_energy_data, f, ensure_ascii=False)

            with open(time_path, 'w', encoding='utf-8') as f:
                json.dump(sample_time_direction_data, f, ensure_ascii=False)

            generator = DailyMarkdownGenerator(energy_path, time_path)

            # ì£¼ìš” ì„¹ì…˜ ìƒì„±
            summary = generator.generate_summary()
            rhythm_expl = generator.generate_rhythm_explanation()
            action_guide = generator.generate_action_guide()

            # ìš”ì•½ì€ 2ë¬¸ì¥ ì´ìƒ
            sentences_in_summary = len(re.split(r'[.!?]', summary.strip()))
            assert sentences_in_summary >= 2, f"ìš”ì•½ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: {sentences_in_summary}ê°œ ë¬¸ì¥"

            # ë¦¬ë“¬ í•´ì„¤ì€ 2ë¬¸ë‹¨ ì´ìƒ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” 2ë¬¸ë‹¨)
            paragraphs_in_rhythm = len(rhythm_expl.split('\n\n'))
            assert paragraphs_in_rhythm >= 2, f"ë¦¬ë“¬ í•´ì„¤ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: {paragraphs_in_rhythm}ê°œ ë¬¸ë‹¨"

            # í–‰ë™ ê°€ì´ë“œëŠ” êµ¬ì¡°í™”ë˜ì–´ ìˆì–´ì•¼ í•¨
            assert "ê¶Œì¥" in action_guide or "Do" in action_guide or "í•˜ê¸°" in action_guide
            assert "ì§€ì–‘" in action_guide or "Avoid" in action_guide or "í”¼í•˜ê¸°" in action_guide


# ============================================================================
# TEST 3: Markdown Generation Format
# ============================================================================

class TestMarkdownGeneration:
    """Markdown ìƒì„± í˜•ì‹ ê²€ì¦"""

    def test_all_required_sections_present(self, sample_energy_data, sample_time_direction_data):
        """í•„ìˆ˜ ì„¹ì…˜ í¬í•¨ í™•ì¸"""
        import tempfile
        import os

        with tempfile.TemporaryDirectory() as tmpdir:
            energy_path = os.path.join(tmpdir, "energy.json")
            time_path = os.path.join(tmpdir, "time.json")

            with open(energy_path, 'w', encoding='utf-8') as f:
                json.dump(sample_energy_data, f, ensure_ascii=False)

            with open(time_path, 'w', encoding='utf-8') as f:
                json.dump(sample_time_direction_data, f, ensure_ascii=False)

            generator = DailyMarkdownGenerator(energy_path, time_path)
            markdown = generator.generate_markdown()

            # í•„ìˆ˜ ì„¹ì…˜ í™•ì¸
            required_sections = [
                "# ì˜¤ëŠ˜ì˜ ì•ˆë‚´",
                "## ìš”ì•½",
                "## í‚¤ì›Œë“œ",
                "## ë¦¬ë“¬ í•´ì„¤",
                "## ì§‘ì¤‘/ì£¼ì˜ í¬ì¸íŠ¸",
                "## í–‰ë™ ê°€ì´ë“œ",
                "## ì‹œê°„/ë°©í–¥",
                "## ìƒíƒœ ì „í™˜ íŠ¸ë¦¬ê±°",
                "## ì˜ë¯¸ ì „í™˜",
                "## ë¦¬ë“¬ ì§ˆë¬¸",
                "---",  # êµ¬ë¶„ì„ 
            ]

            for section in required_sections:
                assert section in markdown, f"í•„ìˆ˜ ì„¹ì…˜ '{section}'ì´ ì—†ìŠµë‹ˆë‹¤"

    def test_emoji_rendering(self, sample_energy_data, sample_time_direction_data):
        """ì´ëª¨ì§€ ë Œë”ë§ í™•ì¸"""
        import tempfile
        import os

        with tempfile.TemporaryDirectory() as tmpdir:
            energy_path = os.path.join(tmpdir, "energy.json")
            time_path = os.path.join(tmpdir, "time.json")

            with open(energy_path, 'w', encoding='utf-8') as f:
                json.dump(sample_energy_data, f, ensure_ascii=False)

            with open(time_path, 'w', encoding='utf-8') as f:
                json.dump(sample_time_direction_data, f, ensure_ascii=False)

            generator = DailyMarkdownGenerator(energy_path, time_path)
            lifestyle_sections = generator.generate_lifestyle_sections()

            # ì´ëª¨ì§€ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            emojis = ["ğŸƒ", "ğŸœ", "ğŸ‘”", "ğŸ’°", "ğŸ ", "â°", "ğŸ“±", "ğŸ¨", "ğŸ¤", "â„ï¸"]

            # ì ì–´ë„ ì¼ë¶€ ì´ëª¨ì§€ëŠ” í¬í•¨ë˜ì–´ì•¼ í•¨
            emoji_count = sum(1 for emoji in emojis if emoji in lifestyle_sections)
            assert emoji_count > 0, "ìƒí™œ ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ì— ì´ëª¨ì§€ê°€ ì—†ìŠµë‹ˆë‹¤"

    def test_markdown_format_validity(self, sample_energy_data, sample_time_direction_data):
        """Markdown í˜•ì‹ ìœ íš¨ì„± í™•ì¸"""
        import tempfile
        import os

        with tempfile.TemporaryDirectory() as tmpdir:
            energy_path = os.path.join(tmpdir, "energy.json")
            time_path = os.path.join(tmpdir, "time.json")

            with open(energy_path, 'w', encoding='utf-8') as f:
                json.dump(sample_energy_data, f, ensure_ascii=False)

            with open(time_path, 'w', encoding='utf-8') as f:
                json.dump(sample_time_direction_data, f, ensure_ascii=False)

            generator = DailyMarkdownGenerator(energy_path, time_path)
            markdown = generator.generate_markdown()

            # ì œëª© ë ˆë²¨ í™•ì¸
            assert "# " in markdown  # H1
            assert "## " in markdown  # H2

            # ë¦¬ìŠ¤íŠ¸ í˜•ì‹ í™•ì¸
            assert "- " in markdown  # Unordered list

            # ê°•ì¡° í˜•ì‹ í™•ì¸
            assert "**" in markdown  # Bold

    def test_desktop_example_structure_match(self, sample_energy_data, sample_time_direction_data):
        """ë°ìŠ¤í¬íƒ‘ ì˜ˆì œì™€ êµ¬ì¡° ì¼ì¹˜ í™•ì¸"""
        import tempfile
        import os

        with tempfile.TemporaryDirectory() as tmpdir:
            energy_path = os.path.join(tmpdir, "energy.json")
            time_path = os.path.join(tmpdir, "time.json")

            with open(energy_path, 'w', encoding='utf-8') as f:
                json.dump(sample_energy_data, f, ensure_ascii=False)

            with open(time_path, 'w', encoding='utf-8') as f:
                json.dump(sample_time_direction_data, f, ensure_ascii=False)

            generator = DailyMarkdownGenerator(energy_path, time_path)
            markdown = generator.generate_markdown()

            # êµ¬ì¡° ê²€ì¦
            lines = markdown.split('\n')

            # ì²« ë²ˆì§¸ ì¤„ì€ ì œëª©
            assert lines[0].startswith("# "), "ì²« ë²ˆì§¸ ì¤„ì´ ì œëª©ì´ ì•„ë‹™ë‹ˆë‹¤"

            # ì„¹ì…˜ ë¶„í¬ í™•ì¸
            section_count = markdown.count("## ")
            assert section_count >= 8, f"ì„¹ì…˜ì´ ë¶€ì¡±í•©ë‹ˆë‹¤: {section_count}ê°œ (ìµœì†Œ 8ê°œ í•„ìš”)"


# ============================================================================
# TEST 4: API Endpoints
# ============================================================================

class TestAPIEndpoints:
    """API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def test_files_setup(self, sample_energy_data, sample_time_direction_data):
        """í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ ìƒì„±"""
        from pathlib import Path

        daily_dir = Path(__file__).parent / "daily"
        daily_dir.mkdir(parents=True, exist_ok=True)

        energy_path = daily_dir / "today_energy_simple.json"
        time_path = daily_dir / "today_time_direction_simple.json"

        with open(energy_path, 'w', encoding='utf-8') as f:
            json.dump(sample_energy_data, f, ensure_ascii=False, indent=2)

        with open(time_path, 'w', encoding='utf-8') as f:
            json.dump(sample_time_direction_data, f, ensure_ascii=False, indent=2)

        yield energy_path, time_path

        # ì •ë¦¬
        energy_path.unlink(missing_ok=True)
        time_path.unlink(missing_ok=True)

    def test_markdown_file_generation(self, test_files_setup, sample_energy_data, sample_time_direction_data):
        """Markdown íŒŒì¼ ìƒì„± í…ŒìŠ¤íŠ¸"""
        import tempfile
        import os

        energy_path, time_path = test_files_setup

        generator = DailyMarkdownGenerator(str(energy_path), str(time_path))
        output_dir = Path(__file__).parent / "daily_test"
        output_dir.mkdir(parents=True, exist_ok=True)

        output_path = generator.save_markdown(
            output_dir=str(output_dir),
            date_str="2026-01-31"
        )

        # íŒŒì¼ ìƒì„± í™•ì¸
        assert output_path.exists()
        assert output_path.suffix == ".md"

        # íŒŒì¼ ë‚´ìš© í™•ì¸
        content = output_path.read_text(encoding='utf-8')
        assert len(content) > 0
        assert "# ì˜¤ëŠ˜ì˜ ì•ˆë‚´" in content

        # ì •ë¦¬
        output_path.unlink(missing_ok=True)
        output_dir.rmdir()

    def test_get_daily_markdown_endpoint_simulation(self, test_files_setup):
        """GET /api/daily/{date}/markdown ì—”ë“œí¬ì¸íŠ¸ ì‹œë®¬ë ˆì´ì…˜"""
        energy_path, time_path = test_files_setup

        # ì—”ë“œí¬ì¸íŠ¸ ë¡œì§ ì‹œë®¬ë ˆì´ì…˜
        daily_dir = Path(__file__).parent / "daily"
        md_file = daily_dir / "2026-01-31_new_format.md"

        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ í˜•ì‹ íŒŒì¼ë„ í™•ì¸
        if not md_file.exists():
            md_file = daily_dir / "2026-01-31.md"

        # ì´ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸
        # ì‹¤ì œ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ëŠ” API í…ŒìŠ¤íŠ¸ì—ì„œ ìˆ˜í–‰
        if md_file.exists():
            markdown_content = md_file.read_text(encoding='utf-8')
            assert isinstance(markdown_content, str)
            assert len(markdown_content) > 0

    def test_get_daily_markdown_html_endpoint_simulation(self, test_files_setup):
        """GET /api/daily/{date}/markdown-html ì—”ë“œí¬ì¸íŠ¸ ì‹œë®¬ë ˆì´ì…˜"""
        import markdown as md_lib

        if not hasattr(md_lib, 'markdown'):
            pytest.skip("markdown ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        energy_path, time_path = test_files_setup

        # ë§ˆí¬ë‹¤ìš´ -> HTML ë³€í™˜ ì‹œë®¬ë ˆì´ì…˜
        sample_md = "# í…ŒìŠ¤íŠ¸\n\nì˜¤ëŠ˜ì€ ì¢‹ì€ ë‚ ì…ë‹ˆë‹¤.\n\n- í•­ëª©1\n- í•­ëª©2"

        try:
            html_content = md_lib.markdown(sample_md)
            assert isinstance(html_content, str)
            assert "<h1>" in html_content or "<H1>" in html_content
        except:
            pytest.skip("ë§ˆí¬ë‹¤ìš´ HTML ë³€í™˜ ì‹¤íŒ¨")

    def test_error_handling_missing_date(self):
        """ë‚ ì§œê°€ ì—†ì„ ë•Œ ì—ëŸ¬ ì²˜ë¦¬"""
        # 404 ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦
        daily_dir = Path(__file__).parent / "daily"
        non_existent_file = daily_dir / "1900-01-01.md"

        assert not non_existent_file.exists(), "í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤"


# ============================================================================
# TEST 5: Complete Pipeline Integration
# ============================================================================

class TestPipeline:
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_complete_generation_pipeline(self, test_birth_info, test_target_date, sample_energy_data, sample_time_direction_data):
        """ì™„ì „í•œ ì¼ê°„ ì½˜í…ì¸  ìƒì„± íŒŒì´í”„ë¼ì¸"""
        import tempfile
        import os

        with tempfile.TemporaryDirectory() as tmpdir:
            # Step 1: Saju ê³„ì‚°
            try:
                saju_result = calculate_saju(test_birth_info, test_target_date)
                assert isinstance(saju_result, dict)
            except RuntimeError as e:
                if "cli.js" in str(e) or "node" in str(e).lower():
                    pytest.skip(f"Saju ê³„ì‚°ê¸° ë¶€ì¬: {e}")
                raise

            # Step 2: ì¼ê°„ ë¶„ì„
            from src.rhythm.saju import analyze_daily_fortune as analyze_fortune
            fortune = analyze_fortune(test_birth_info, test_target_date, saju_result)
            assert isinstance(fortune, dict)

            # Step 3: ì½˜í…ì¸  ì¡°ë¦½
            daily_rhythm = {
                "ì—ë„ˆì§€_ìˆ˜ì¤€": 4,
                "ì§‘ì¤‘ë ¥": 4,
                "ì‚¬íšŒìš´": 3,
                "ê²°ì •ë ¥": 4,
                "ìœ ë¦¬í•œ_ì‹œê°„": ["ì˜¤ì „ 9-11ì‹œ", "ì˜¤í›„ 2-4ì‹œ"],
                "ì£¼ì˜_ì‹œê°„": ["ì˜¤í›„ 5-7ì‹œ"],
                "ìœ ë¦¬í•œ_ë°©í–¥": ["ë¶ë™", "ë‚¨"],
                "ì£¼ì˜_ë°©í–¥": ["ì„œ"],
                "ì£¼ìš”_íë¦„": "í™œë™ê³¼ ê²°ì •",
                "ê¸°íšŒ_ìš”ì†Œ": ["ë¦¬ë”ì‹­", "ê²°ì •"],
                "ë„ì „_ìš”ì†Œ": ["ê³¼ìš•", "ì†Œí†µ"]
            }

            content = assemble_daily_content(
                date=test_target_date,
                saju_data=saju_result,
                daily_rhythm=daily_rhythm
            )
            assert isinstance(content, dict)
            assert content["date"] == "2026-01-31"

            # Step 4: Markdown ìƒì„±
            energy_path = os.path.join(tmpdir, "energy.json")
            time_path = os.path.join(tmpdir, "time.json")

            with open(energy_path, 'w', encoding='utf-8') as f:
                json.dump(sample_energy_data, f, ensure_ascii=False)

            with open(time_path, 'w', encoding='utf-8') as f:
                json.dump(sample_time_direction_data, f, ensure_ascii=False)

            generator = DailyMarkdownGenerator(energy_path, time_path)
            markdown = generator.generate_markdown()

            # ìµœì¢… ê²€ì¦
            assert isinstance(markdown, str)
            assert len(markdown) > 400
            assert "# ì˜¤ëŠ˜ì˜ ì•ˆë‚´" in markdown
            assert "## ìš”ì•½" in markdown

    def test_output_file_creation(self, sample_energy_data, sample_time_direction_data):
        """ì¶œë ¥ íŒŒì¼ ìƒì„± í™•ì¸"""
        import tempfile
        import os

        with tempfile.TemporaryDirectory() as tmpdir:
            energy_path = os.path.join(tmpdir, "energy.json")
            time_path = os.path.join(tmpdir, "time.json")

            with open(energy_path, 'w', encoding='utf-8') as f:
                json.dump(sample_energy_data, f, ensure_ascii=False)

            with open(time_path, 'w', encoding='utf-8') as f:
                json.dump(sample_time_direction_data, f, ensure_ascii=False)

            generator = DailyMarkdownGenerator(energy_path, time_path)

            # ì¶œë ¥ ë””ë ‰í† ë¦¬
            output_dir = Path(tmpdir) / "output"
            output_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ì €ì¥
            output_path = generator.save_markdown(
                output_dir=str(output_dir),
                date_str="2026-01-31-test"
            )

            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            assert output_path.exists()
            assert output_path.name == "2026-01-31-test.md"

            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = output_path.stat().st_size
            assert file_size > 400, f"íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {file_size} bytes"

    def test_content_quality_metrics(self, sample_energy_data, sample_time_direction_data):
        """ì½˜í…ì¸  í’ˆì§ˆ ì§€í‘œ ê²€ì¦"""
        import tempfile
        import os

        with tempfile.TemporaryDirectory() as tmpdir:
            energy_path = os.path.join(tmpdir, "energy.json")
            time_path = os.path.join(tmpdir, "time.json")

            with open(energy_path, 'w', encoding='utf-8') as f:
                json.dump(sample_energy_data, f, ensure_ascii=False)

            with open(time_path, 'w', encoding='utf-8') as f:
                json.dump(sample_time_direction_data, f, ensure_ascii=False)

            generator = DailyMarkdownGenerator(energy_path, time_path)

            # ê° ì„¹ì…˜ ê²€ì¦
            summary = generator.generate_summary()
            assert len(summary) >= 50, "ìš”ì•½ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤"

            keywords = generator.generate_keywords()
            assert len(keywords) > 0, "í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤"
            assert "â€¢" in keywords, "í‚¤ì›Œë“œ êµ¬ë¶„ì´ ì—†ìŠµë‹ˆë‹¤"

            rhythm_expl = generator.generate_rhythm_explanation()
            assert len(rhythm_expl) >= 200, "ë¦¬ë“¬ í•´ì„¤ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤"

            focus_attention = generator.generate_focus_attention()
            assert "ì§‘ì¤‘" in focus_attention or "ì£¼ì˜" in focus_attention

            action_guide = generator.generate_action_guide()
            assert "ê¶Œì¥" in action_guide or "ì§€ì–‘" in action_guide

            time_direction = generator.generate_time_direction()
            assert "ì‹œê°„" in time_direction or "ë°©í–¥" in time_direction


# ============================================================================
# RUN TESTS
# ============================================================================

if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
